kafka-run-class.sh kafka.tools.ProducerPerformance \
  --topic my_topic \
  --num-records 100000 \
  --record-size 100 \
  --throughput -1 \
  --producer-props bootstrap.servers=kafka:9092

Le LAG Kafka représente le nombre de messages en attente de traitement par les consommateurs. Dans ton cas, après l’incident de stockage, le LAG est passé de 8M à 38M, ce qui signifie que les consommateurs n’ont pas pu traiter les messages en temps réel et ont pris du retard.

📌 Cause principale du problème :
	1.	Stockage plein → Kafka ne pouvait plus écrire de nouveaux messages, ce qui a interrompu le traitement normal des consommateurs.
	2.	Redémarrage du cluster → Une fois l’espace disque libéré, les producteurs ont recommencé à envoyer des messages, mais les consommateurs avaient un énorme retard à rattraper.
	3.	Génération rapide de nouveaux messages → Pendant que les consommateurs essaient de rattraper leur retard, de nouveaux messages continuent d’arriver, augmentant encore le LAG.
	4.	Débit des consommateurs insuffisant → Si Logstash ne consomme pas assez vite, il ne peut pas réduire le LAG efficacement.

📌 Comment résoudre le problème ?

1️⃣ Vérifier la capacité des consumers Logstash

Tes consumers peuvent être limités par plusieurs facteurs :
✅ CPU & RAM : Vérifie que Logstash n’est pas CPU ou RAM-bound. S’il est en surcharge, il ne pourra pas traiter les messages rapidement.
✅ Workers et Threads : Vérifie la configuration de pipeline.workers et pipeline.batch.size dans Logstash (logstash.yml). Tu peux augmenter :

pipeline.workers: 4  # Augmente si la machine a plus de CPU
pipeline.batch.size: 200
pipeline.batch.delay: 50

✅ Parallelisme Kafka Input : Si tu utilises logstash-input-kafka, assure-toi d’avoir plusieurs threads (consumer_threads):

input {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092,kafka3:9092"
    topics => ["mon_topic"]
    group_id => "logstash_group"
    consumer_threads => 4  # Augmente le nombre de threads
  }
}

2️⃣ Vérifier la charge du cluster Kafka

✅ Nombre de partitions par topic :
	•	Plus tu as de partitions, plus les consommateurs peuvent lire en parallèle.
	•	Vérifie avec la commande :

kafka-topics.sh --describe --topic mon_topic --bootstrap-server kafka:9092


	•	Si ton topic n’a qu’une ou deux partitions et plusieurs consommateurs, il peut y avoir une saturation. Dans ce cas, augmente le nombre de partitions :

kafka-topics.sh --alter --topic mon_topic --partitions 10 --bootstrap-server kafka:9092

⚠️ Attention : Ne change pas le nombre de partitions une fois un topic en production sans bien gérer le rebalancement !

✅ Charge des Brokers Kafka :
	•	Vérifie l’utilisation CPU/Mémoire/Disque des brokers.
	•	Vérifie la répartition des partitions sur les brokers avec :

kafka-replica-verification.sh --broker-list 0,1,2 --topic mon_topic


	•	Assure-toi que la réplication et les ISR (In-Sync Replicas) sont bien équilibrés.

3️⃣ Accélérer la consommation des messages pour rattraper le LAG

Si le débit actuel ne suffit pas à rattraper le retard, voici quelques stratégies :

✅ Ajouter plus de consommateurs Logstash (scalabilité horizontale)
	•	Si un seul Logstash tourne, lance plusieurs instances avec le même group_id.
	•	Exécute plusieurs containers ou services Logstash pour paralléliser la consommation.

✅ Augmenter fetch_max_bytes et max_partition_fetch_bytes
	•	Kafka ne lit que des petits lots de messages par défaut, ce qui peut limiter la vitesse.
	•	Dans Logstash Kafka Input, augmente la taille du fetch :

input {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092,kafka3:9092"
    topics => ["mon_topic"]
    group_id => "logstash_group"
    consumer_threads => 4
    max_partition_fetch_bytes => "10485760"  # 10MB
    fetch_max_bytes => "10485760"  # 10MB
  }
}



✅ Activer auto.commit.interval.ms pour éviter de re-lire des messages
	•	Kafka peut re-lire certains messages si la confirmation de lecture (commit) est trop lente.
	•	Active un intervalle plus rapide dans Logstash :

input {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092,kafka3:9092"
    topics => ["mon_topic"]
    group_id => "logstash_group"
    consumer_threads => 4
    enable_auto_commit => "true"
    auto_commit_interval_ms => "1000"
  }
}



✅ Utiliser auto.offset.reset=earliest si des messages sont perdus
	•	Si tu vois des gaps dans les logs et que Kafka ne consomme pas les anciens messages :

input {
  kafka {
    bootstrap_servers => "kafka1:9092,kafka2:9092,kafka3:9092"
    topics => ["mon_topic"]
    group_id => "logstash_group"
    auto_offset_reset => "earliest"
  }
}



⚠️ Attention : Cela peut forcer la relecture de tous les messages si le groupe de consommateurs est nouveau.

📌 Conclusion :

✅ Problème principal :
	•	Le stockage plein a bloqué Kafka, et après redémarrage, les consumers n’ont pas rattrapé le LAG.
	•	Le LAG continue d’augmenter car les consommateurs ne traitent pas assez rapidement les messages.

✅ Solutions recommandées :
	1.	Augmenter les threads Logstash (consumer_threads + pipeline.workers).
	2.	Ajouter plus de partitions pour permettre plus de lecture en parallèle.
	3.	Augmenter fetch_max_bytes pour lire plus de messages par batch.
	4.	Déployer plusieurs instances de Logstash pour répartir la charge.
	5.	Activer auto.commit.interval.ms pour éviter de re-lire trop de messages.
	6.	Surveiller les brokers Kafka et équilibrer la charge.

💡 Avec ces optimisations, ton Logstash pourra consommer plus rapidement et réduire le LAG ! 🚀


input {
  file {
    path => "/var/log/audit/audit.log"
    type => "audit"
    start_position => "beginning"
  }
}

filter {
  # Parser le type d'événement et le message initial
  grok {
    match => {
      "message" => [
        "^type=%{WORD:audit_type}\s+msg=audit\(%{NUMBER:epoch_time}(?:\.\d+)?(:%{NUMBER:audit_sequence})?\):\s*(?<audit_message>.*)$"
      ]
    }
  }

  # Convertir le temps epoch en @timestamp
  date {
    match => [ "epoch_time", "UNIX" ]
    target => "@timestamp"
    remove_field => [ "epoch_time" ]
  }

  # Parser les paires clé-valeur dans audit_message
  kv {
    source => "audit_message"
    field_split_pattern => "\s+"
    value_split => "="
    include_brackets => false
    trim_value => "\"'"
  }

  # Traiter les valeurs spécifiques en fonction du type d'audit
  if [audit_type] == "SYSCALL" {
    # Convertir certains champs en types appropriés
    mutate {
      convert => {
        "pid" => "integer"
        "ppid" => "integer"
        "uid" => "integer"
        "gid" => "integer"
        "euid" => "integer"
        "egid" => "integer"
        "auid" => "integer"
        "ses" => "integer"
        "exit" => "integer"
        "success" => "string"
      }
      lowercase => [ "success" ]
    }
  } else if [audit_type] == "EXECVE" {
    # Combiner les arguments du processus
    mutate {
      rename => { "argc" => "arg_count" }
    }
  } else if [audit_type] == "CWD" {
    # Aucun traitement spécifique nécessaire
  } else if [audit_type] == "PATH" {
    # Gérer les chemins de fichiers
    mutate {
      rename => { "name" => "file_path" }
    }
  } else if [audit_type] in ["USER_AUTH", "USER_LOGIN"] {
    # Gérer les événements d'authentification utilisateur
    mutate {
      convert => {
        "pid" => "integer"
        "uid" => "integer"
        "auid" => "integer"
        "ses" => "integer"
      }
    }
  } else if [audit_type] in ["USER_START", "USER_END"] {
    # Gérer le début et la fin des sessions utilisateur
    mutate {
      convert => {
        "pid" => "integer"
        "uid" => "integer"
        "auid" => "integer"
        "ses" => "integer"
      }
    }
  } else if [audit_type] in ["CRED_ACQ", "CRED_DISP"] {
    # Gérer l'acquisition et la libération des informations d'identification
    mutate {
      convert => {
        "pid" => "integer"
        "uid" => "integer"
        "auid" => "integer"
        "ses" => "integer"
      }
    }
  } else if [audit_type] == "CONFIG_CHANGE" {
    # Gérer les changements de configuration
    mutate {
      convert => {
        "auid" => "integer"
        "pid" => "integer"
        "ses" => "integer"
        "res" => "string"
      }
      lowercase => [ "res" ]
    }
  } else if [audit_type] in ["DAEMON_START", "DAEMON_END"] {
    # Gérer le démarrage et l'arrêt du démon d'audit
    mutate {
      convert => {
        "pid" => "integer"
        "uid" => "integer"
        "auid" => "integer"
        "ses" => "integer"
      }
    }
  } else if [audit_type] == "AVC" {
    # Gérer les événements SELinux AVC
    mutate {
      rename => {
        "scontext" => "source_context"
        "tcontext" => "target_context"
        "tclass" => "target_class"
      }
    }
  }

  # Nettoyer les champs inutiles
  mutate {
    remove_field => [ "message", "audit_message" ]
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "linux-audit-%{+YYYY.MM.dd}"
  }
}

filter {
  # Parser le type d'audit et le message initial
  grok {
    match => {
      "message" => "^type=%{WORD:audit_type}\\s+msg=audit\\(%{NUMBER:epoch_time}(?:\\.\\d+)?(?::%{NUMBER:audit_sequence})?\\):\\s*(?<audit_message>.*)$"
    }
  }

  # Convertir le temps epoch en @timestamp
  date {
    match => [ "epoch_time", "UNIX" ]
    target => "@timestamp"
    remove_field => [ "epoch_time" ]
  }

  # Parser les paires clé-valeur dans audit_message
  kv {
    source => "audit_message"
    field_split_pattern => "\\s+"
    value_split => "="
    include_brackets => false
    trim_value => "\"'"
  }

  # Transformations communes pour tous les types d'audit
  mutate {
    # Conversion des champs numériques
    convert => {
      "pid" => "integer"
      "ppid" => "integer"
      "uid" => "integer"
      "euid" => "integer"
      "gid" => "integer"
      "egid" => "integer"
      "auid" => "integer"
      "ses" => "integer"
      "exit" => "integer"
    }
    # Uniformisation des champs de résultat
    lowercase => [ "success", "res" ]
    # Renommage des champs pour une meilleure clarté
    rename => {
      "argc" => "arg_count"
      "name" => "file_path"
    }
    # Suppression des champs temporaires
    remove_field => [ "message", "audit_message" ]
  }

  # Spécifique pour audit_type = AVC ou USER_AVC
  if [audit_type] in ["AVC", "USER_AVC"] {
    # Extraire le message AVC
    grok {
      match => {
        "msg" => "avc:\\s+%{WORD:avc_action}\\s+\\{\\s*%{WORD:avc_permission}\\s*\\}\\s+for\\s+pid=%{NUMBER:pid}(?:\\s+comm=\"%{DATA:comm}\")?(?:\\s+name=\"%{DATA:file_path}\")?\\s+dev=\"%{DATA:dev}\"\\s+ino=%{NUMBER:inode}\\s+scontext=%{DATA:scontext}\\s+tcontext=%{DATA:tcontext}\\s+tclass=%{DATA:tclass}"
      }
    }
    # Renommer les champs contextuels
    mutate {
      rename => {
        "scontext" => "source_context"
        "tcontext" => "target_context"
        "tclass" => "target_class"
      }
    }
  }
}
filter {
  # Parser le type d'audit et le message initial
  grok {
    match => {
      "message" => "^type=%{WORD:audit_type}\\s+msg=audit\\(%{NUMBER:epoch_time}(?:\\.\\d+)?(?::%{NUMBER:audit_sequence})?\\):\\s*(?<audit_message>.*)$"
    }
  }

  # Convertir le temps epoch en @timestamp
  date {
    match => [ "epoch_time", "UNIX" ]
    target => "@timestamp"
    remove_field => [ "epoch_time" ]
  }

  # Parser les paires clé-valeur dans audit_message
  kv {
    source => "audit_message"
    field_split_pattern => "\\s+"
    value_split => "="
    include_brackets => false
    trim_value => "\"'"
  }

  # Transformations communes pour tous les types d'audit
  mutate {
    # Conversion des champs numériques
    convert => {
      "pid" => "integer"
      "ppid" => "integer"
      "uid" => "integer"
      "euid" => "integer"
      "gid" => "integer"
      "egid" => "integer"
      "auid" => "integer"
      "ses" => "integer"
      "exit" => "integer"
    }
    # Uniformisation des champs de résultat
    lowercase => [ "success", "res" ]
    # Renommage des champs pour une meilleure clarté
    rename => {
      "argc" => "arg_count"
      "name" => "file_path"
    }
    # Suppression des champs temporaires
    remove_field => [ "message", "audit_message" ]
  }

  # Spécifique pour audit_type = AVC ou USER_AVC
  if [audit_type] in ["AVC", "USER_AVC"] {
    # Utiliser grok pour parser jusqu'à "} for"
    grok {
      match => {
        "msg" => "avc:\\s+%{WORD:avc_action}\\s+\\{\\s*%{WORD:avc_permission}\\s*\\}\\s+for\\s*(?<remaining_msg>.*)"
      }
    }

    # Utiliser kv pour le reste du message
    kv {
      source => "remaining_msg"
      field_split_pattern => "\\s+"
      value_split => "="
      trim_value => "\"'"
    }

    # Renommer les champs contextuels
    mutate {
      rename => {
        "scontext" => "source_context"
        "tcontext" => "target_context"
        "tclass" => "target_class"
      }
      remove_field => [ "remaining_msg" ]
    }
  }
}

filter {
  # Étape 1 : Arrondir le timestamp à la seconde pour ignorer les millisecondes
  ruby {
    code => "
      event.set('rounded_timestamp', event.get('@timestamp').time.strftime('%Y-%m-%d %H:%M:%S'))
    "
  }

  # Étape 2 : Générer un hash unique basé sur les champs clés (excluant les millisecondes)
  fingerprint {
    source => ["rounded_timestamp", "program", "message"]
    target => "message_hash"
    method => "SHA1"
  }

  # Étape 3 : Utiliser l'aggregate filter pour détecter et ignorer les doublons
  aggregate {
    task_id => "%{message_hash}"
    code => "
      map['count'] ||= 0;
      map['count'] += 1;
      if (map['count'] > 1)
        event.cancel()
    "
    timeout => 60 # Cache chaque message unique pendant 60 secondes
  }

  # Optionnel : Ajouter un tag si un doublon est détecté pour une analyse ultérieure
  if [message_hash] and [count] > 1 {
    mutate {
      add_tag => ["_duplicate"]
    }
  }

  # Supprimer le champ temporaire 'rounded_timestamp'
  mutate {
    remove_field => ["rounded_timestamp"]
  }
}
