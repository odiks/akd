Kafka File Transfer
Ce projet fournit une solution robuste et s√©curis√©e pour transf√©rer des fichiers de toute taille via Apache Kafka. Il est compos√© d'un producteur (pour envoyer des fichiers) et d'un consommateur (pour les recevoir et les reconstruire), con√ßus pour √™tre r√©silients, performants et exploitables en environnement de production.

Table des Mati√®res
Fonctionnalit√©s Cl√©s
Architecture
Concepts de S√©curit√©
D√©marrage Rapide
Pr√©requis
Compilation
Ex√©cution
Configuration
Fichier producer.properties
Fichier consumer.properties
Modes d'Op√©ration Sp√©ciaux
Mode de D√©bogage (JSON)
Mode de R√©cup√©ration d'Urgence
Structure du Projet
Am√©liorations Futures
Fonctionnalit√©s Cl√©s
‚úÖ Support des Fichiers Volumineux : Les fichiers sont d√©coup√©s en chunks et stream√©s, √©vitant de charger des fichiers entiers en m√©moire.
‚úÖ Transfert Complet des M√©tadonn√©es : Conserve les permissions (POSIX & Windows ACLs), les timestamps, et les informations de propri√©taire.
‚úÖ Int√©grit√© des Donn√©es Garantie : Un hash cryptographique (SHA-256/384/512) du fichier complet est calcul√© et v√©rifi√© √† la r√©ception.
‚úÖ Confidentialit√© de Bout-en-Bout (Optionnel) : Chiffrement hybride robuste (RSA/AES-GCM) pour s'assurer que seul le destinataire peut lire les fichiers.
‚úÖ Compression des Donn√©es (Optionnel) : Compresse les chunks (Gzip, Snappy) pour r√©duire l'utilisation de la bande passante et du stockage.
‚úÖ Robustesse et Fiabilit√© : Con√ßu pour √™tre r√©silient face aux pannes, avec des configurations de producteur idempotentes (acks=all).
‚úÖ Tra√ßabilit√© : Logging structur√© et d√©taill√© incluant un ID de transfert unique (TID) pour suivre un fichier de bout en bout.
‚úÖ Reprise sur Sinistre : Un mode de r√©cup√©ration permet de reconstruire un fichier sp√©cifique √† partir des donn√©es pr√©sentes dans Kafka, m√™me apr√®s une suppression locale.
Architecture
Le syst√®me suit un flux de donn√©es simple mais puissant, orchestr√© par Apache Kafka.

Producteur -> [ Topic de Donn√©es Kafka ] -> Consommateur

Producteur
Le producteur est une application en ligne de commande qui prend un fichier en entr√©e et ex√©cute les √©tapes suivantes :

G√©n√®re un ID de Transfert unique (UUID).
Lit toutes les m√©tadonn√©es du fichier (taille, permissions, dates, etc.).
Calcule le hash cryptographique du fichier complet pour garantir l'int√©grit√©.
Lit le fichier chunk par chunk pour ne pas saturer la m√©moire.
Pour chaque chunk :
Le compresse (si activ√©).
Le chiffre (si activ√©).
Calcule son propre hash.
Envoie chaque chunk sous forme de message √† un topic Kafka. Le transferId est utilis√© comme cl√© de message pour garantir que tous les chunks d'un m√™me fichier arrivent sur la m√™me partition, pr√©servant ainsi leur ordre.
Envoie un message final (sans donn√©es) contenant toutes les m√©tadonn√©es de reconstruction (cl√©s de chiffrement, etc.).
Consommateur
Le consommateur est un service longue dur√©e qui √©coute le topic Kafka :

Il lit les messages et regroupe les chunks par transferId dans un r√©pertoire de transit (staging) sur le disque.
Lorsqu'il re√ßoit le message final et qu'il a collect√© tous les chunks de donn√©es, il d√©marre la reconstruction :
Il assemble les chunks dans l'ordre dans un fichier temporaire.
Pendant l'assemblage, il d√©chiffre et d√©compresse chaque chunk si n√©cessaire.
Une fois le fichier temporaire assembl√©, il v√©rifie son int√©grit√© en comparant son hash avec le hash original.
Si l'int√©grit√© est valid√©e, il applique les m√©tadonn√©es (permissions, timestamps) au fichier.
Finalement, il d√©place atomiquement le fichier temporaire vers sa destination finale, le rendant visible aux autres applications.
Il nettoie le r√©pertoire de transit.
Concepts de S√©curit√©
Principe	Statut	M√©canisme d'Impl√©mentation
Confidentialit√©	‚úÖ Impl√©ment√©	Chiffrement de bout-en-bout (Hybride RSA-4096 / AES-256 GCM). Seul le destinataire avec la cl√© priv√©e peut lire les donn√©es.
Int√©grit√©	‚úÖ Impl√©ment√©	Hachage cryptographique (SHA-256 par d√©faut) du fichier complet, v√©rifi√© √† la reconstruction.
Authentification	üü° D√©l√©gu√© √† Kafka	L'application supporte l'authentification via SASL. Il est de la responsabilit√© de l'op√©rateur de configurer les ACLs Kafka.
Autorisation	üü° D√©l√©gu√© √† Kafka	Les ACLs Kafka doivent √™tre configur√©es en production pour restreindre l'acc√®s en lecture/√©criture aux topics et aux consumer groups.
D√©marrage Rapide
Pr√©requis
Java Development Kit (JDK) 11 ou sup√©rieur.
Apache Maven 3.6 ou sup√©rieur.
Un cluster Apache Kafka fonctionnel.
Compilation
Le projet utilise Maven. Pour compiler et cr√©er un "fat jar" ex√©cutable, ex√©cutez la commande suivante √† la racine du projet :

code
Bash
mvn clean install
Le JAR ex√©cutable se trouvera dans le r√©pertoire target/kafka-file-transfer-1.0.5.jar.

Ex√©cution
Envoyer un fichier (Producteur)
code
Bash
java -jar target/kafka-file-transfer-1.0.5.jar producer \
  --config ./config/producer.properties \
  /chemin/vers/mon_fichier.zip
producer: Sp√©cifie que nous lan√ßons le producteur.
--config: Chemin vers le fichier de configuration du producteur.
Le dernier argument est le chemin vers le fichier √† envoyer.
Recevoir des fichiers (Consommateur)
code
Bash
java -jar target/kafka-file-transfer-1.0.5.jar consumer \
  --config ./config/consumer.properties \
  --destination-dir /chemin/vers/repertoire_de_sortie
consumer: Sp√©cifie que nous lan√ßons le consommateur.
--config: Chemin vers le fichier de configuration du consommateur.
--destination-dir: Le r√©pertoire o√π les fichiers reconstruits seront sauvegard√©s.
Configuration
Fichier producer.properties
Propri√©t√©	Description	Exemple
bootstrap.servers	Adresses des brokers Kafka.	kafka1:9092,kafka2:9092
topic.data	Le topic o√π les donn√©es des fichiers seront envoy√©es.	files-data-topic
serialization.format	Format des messages. JSON pour le d√©bogage, PROTOBUF pour la production.	JSON
chunk.size	Taille de chaque chunk en octets.	1048576 (1 Mio)
hash.algorithm	Algorithme de hash pour l'int√©grit√©. Options: SHA-256, SHA-384, SHA-512.	SHA-256
compression.algorithm	Algorithme de compression. Options: NONE, GZIP, SNAPPY.	GZIP
encryption.enabled	Activer (true) ou d√©sactiver (false) le chiffrement.	false
encryption.consumer.public_key.path	Chemin vers la cl√© publique du consommateur (obligatoire si chiffrement activ√©).	security/consumer_public.pem
Fichier consumer.properties
Propri√©t√©	Description	Exemple
bootstrap.servers	Adresses des brokers Kafka.	kafka1:9092
group.id	L'ID du groupe de consommateurs. Essentiel pour la reprise sur erreur.	file-reconstructor-group
topic.data	Le topic √† √©couter. Doit √™tre le m√™me que celui du producteur.	files-data-topic
serialization.format	Format des messages. Doit correspondre √† celui du producteur.	JSON
staging.directory	R√©pertoire de stockage temporaire des chunks avant reconstruction.	/tmp/kafka-staging
metadata.restore.permissions	Appliquer (true) ou non (false) les permissions au fichier reconstruit.	true
metadata.restore.owner	Appliquer (true) ou non (false) le propri√©taire/groupe.	false
metadata.restore.timestamps	Appliquer (true) ou non (false) les dates de modification/acc√®s.	true
encryption.private_key.path	Chemin vers la cl√© priv√©e du consommateur (obligatoire si chiffrement activ√©).	security/consumer_private.p8
recovery.transfer.id	(Comment√© par d√©faut) L'ID complet d'un transfert √† r√©cup√©rer.	65b7800b-c8d4-4699...
Modes d'Op√©ration Sp√©ciaux
Mode de D√©bogage (JSON)
Pour inspecter les m√©tadonn√©es envoy√©es dans Kafka et faciliter le d√©bogage, vous pouvez basculer la s√©rialisation en JSON.

Dans producer.properties, d√©finissez : serialization.format=JSON.
Dans consumer.properties, d√©finissez : serialization.format=JSON.
Vous pouvez maintenant utiliser des outils comme kafka-console-consumer pour voir les messages en clair dans le topic. N'oubliez pas de repasser en PROTOBUF pour la production afin de b√©n√©ficier de performances optimales.
Mode de R√©cup√©ration d'Urgence
Si un fichier a √©t√© supprim√© localement mais que ses donn√©es existent toujours dans Kafka (selon la politique de r√©tention), vous pouvez le r√©cup√©rer.

Trouvez l'ID de transfert complet du fichier (par exemple, dans les logs ou les m√©tadonn√©es d'un message JSON).
Ouvrez config/consumer.properties.
D√©commentez la ligne recovery.transfer.id et collez-y l'ID complet.
Lancez le consommateur. Il va lire le topic depuis le d√©but, collecter uniquement les chunks de ce transfert, le reconstruire, puis s'arr√™ter.
Structure du Projet
code
Code
.
‚îú‚îÄ‚îÄ config/                 # Fichiers de configuration externes
‚îú‚îÄ‚îÄ security/               # Cl√©s cryptographiques
‚îú‚îÄ‚îÄ src/main/
‚îÇ   ‚îú‚îÄ‚îÄ java/com/example/kafka/filetransfer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli/            # Logique de la ligne de commande (Picocli)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consumer/       # Logique m√©tier du consommateur
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka/          # Classes d'interaction directe avec Kafka
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/          # Objets de donn√©es (DTO, Config)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ producer/       # Logique m√©tier du producteur
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ service/        # Services techniques (Chiffrement, Hachage, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ proto/              # D√©finition du contrat de donn√©es Protobuf
‚îÇ   ‚îî‚îÄ‚îÄ resources/          # Fichiers de configuration internes (Logback)
‚îú‚îÄ‚îÄ target/                 # JARs compil√©s
‚îú‚îÄ‚îÄ pom.xml                 # D√©pendances et configuration du build Maven
‚îî‚îÄ‚îÄ README.md               # Cette documentation
Am√©liorations Futures
Transactions Kafka : Pour une garantie "tout ou rien" lors de l'envoi des chunks d'un fichier.
Dead-Letter Queue (DLQ) : Pour archiver les transferts qui √©chouent syst√©matiquement √† la reconstruction au lieu de les perdre.
Testabilit√© (Injection de D√©pendances) : Refactoriser les commandes CLI pour permettre des tests unitaires plus faciles.
Suite de Tests Compl√®te : Ajouter des tests unitaires et d'int√©gration (JUnit, Testcontainers).
Signature Num√©rique : Impl√©menter la signature des fichiers pour garantir la non-r√©pudiation (prouver l'identit√© de l'exp√©diteur).



M√©tadonn√©es Pr√©sentes et Compl√®tement Impl√©ment√©es
Les m√©tadonn√©es suivantes sont bien collect√©es par le ManifestService, envoy√©es via Kafka, et peuvent √™tre appliqu√©es par le consommateur :

‚úÖ Nom du fichier (file_name) : Impl√©ment√©.
‚úÖ Taille du fichier (file_size) : Impl√©ment√©e.
‚úÖ Nombre total de chunks (total_chunks) : Impl√©ment√©.
‚úÖ Num√©ro du chunk (chunk_number) : Impl√©ment√©.
‚úÖ Chemin de destination (destination_path) : Impl√©ment√©, mais sa logique d'utilisation √† la reconstruction est implicite (le consommateur √©crit dans le --destination-dir fourni).
‚úÖ Dates (mtime, atime, birthtime) : Compl√®tement impl√©ment√©es.
‚úÖ Permissions (Unix) : Impl√©ment√©es (posix_permissions).
‚úÖ Utilisateur (user), Groupe (group) (Unix) : Impl√©ment√©s (owner_name, group_name).
‚úÖ Hash du fichier (file_hash) : Compl√®tement impl√©ment√© (un des piliers de l'application).
‚úÖ Cl√© publique + chiffrement : Compl√®tement impl√©ment√©.
M√©tadonn√©es Pr√©sentes mais avec des Limitations
üü° ACL (si disponible) : Partiellement impl√©ment√©.
Le code est pr√©sent pour lire les ACLs Windows (AclFileAttributeView) et les appliquer.
Limitation : Cela ne fonctionnera que si le producteur et le consommateur s'ex√©cutent sur des syst√®mes de fichiers compatibles (NTFS vers NTFS) et si les UserPrincipal (utilisateurs/groupes) des ACLs peuvent √™tre r√©solus sur la machine de destination. Le code logue un avertissement si un principal n'est pas trouv√©, ce qui est le bon comportement.
M√©tadonn√©es Non Pr√©sentes dans l'Impl√©mentation Actuelle
Les m√©tadonn√©es suivantes, bien que list√©es dans le cahier des charges, ne sont pas actuellement collect√©es ou trait√©es par l'application :

‚ùå UID, GID (Unix) : Le code g√®re les noms (owner_name, group_name) mais pas les identifiants num√©riques (UID/GID). C'est souvent un meilleur choix car les UID/GID peuvent ne pas correspondre entre diff√©rents syst√®mes, alors que les noms ont plus de chances de l'√™tre (via LDAP/AD par exemple).
‚ùå SID (Windows) : De m√™me, le code g√®re les noms de principaux (BUILTIN\Administrators) mais pas leur Security IDentifier (SID) brut.
‚ùå Permissions (Windows) : Le code g√®re les ACLs, qui est le m√©canisme de permission principal de Windows, mais pas une abstraction plus simple qui pourrait √™tre l'√©quivalent des permissions rwx de POSIX.
‚ùå XATTR (Attributs √âtendus) : Non impl√©ment√©. La lecture des attributs √©tendus (UserDefinedFileAttributeView) n'est pas pr√©sente dans ManifestService.
‚ùå Contexte SELinux : Non impl√©ment√©. C'est une m√©tadonn√©e tr√®s sp√©cifique aux syst√®mes Linux utilisant SELinux. Sa lecture n√©cessiterait l'ex√©cution de commandes syst√®me (ls -Z) ou l'utilisation de biblioth√®ques JNI/JNA.
‚ùå Signature des fichiers : Non impl√©ment√©. Comme discut√©, la logique de signature avec une cl√© priv√©e pour la non-r√©pudiation n'a pas √©t√© ajout√©e.
Tableau R√©capitulatif
M√©tadonn√©e	Statut	Commentaire
Nom, Taille, Chunks, Dates	‚úÖ Impl√©ment√©	Fonctionnalit√© de base, enti√®rement couverte.
Hash Fichier	‚úÖ Impl√©ment√©	Pilier de la fonctionnalit√© d'int√©grit√©.
Chiffrement	‚úÖ Impl√©ment√©	Pilier de la fonctionnalit√© de confidentialit√©.
Permissions POSIX (rwx)	‚úÖ Impl√©ment√©	Couvert pour les syst√®mes de type Unix.
Propri√©taire/Groupe POSIX	‚úÖ Impl√©ment√©	Gestion par nom.
ACLs Windows	üü° Partiellement	Le code existe mais d√©pend de la compatibilit√© des syst√®mes.
UID/GID/SID	‚ùå Non Impl√©ment√©	Gestion par nom uniquement, ce qui est souvent plus portable.
Attributs √âtendus (XATTR)	‚ùå Non Impl√©ment√©	Fonctionnalit√© non couverte.
Contexte SELinux	‚ùå Non Impl√©ment√©	Fonctionnalit√© non couverte, tr√®s sp√©cifique.
Signature des Fichiers	‚ùå Non Impl√©ment√©	La non-r√©pudiation n'est pas couverte.
L'impl√©mentation actuelle couvre donc les exigences les plus critiques et les plus courantes d'un transfert de fichiers multi-plateforme, tout en laissant de c√¥t√© les m√©tadonn√©es les plus exotiques ou sp√©cifiques √† un OS, qui pourraient √™tre ajout√©es comme des am√©liorations futures.
